{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradCam Analysis\n",
    "\n",
    "Note: Reused code from https://towardsdatascience.com/grad-cam-in-pytorch-use-of-forward-and-backward-hooks-7eba5e38d569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/Users/edmundyoung/Desktop/Princeton/Courses/S23/COS429/FinalProject/COS429_FINAL\")\n",
    "sys.path.append(\"/Users/edmundyoung/Desktop/Princeton/Courses/S23/COS429/FinalProject/COS429_FINAL/models\")\n",
    "sys.path.append(\"/Users/edmundyoung/Desktop/Princeton/Courses/S23/COS429/FinalProject/COS429_FINAL/data\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from models import CNNClassifier, CNNEncoderV1, Classifier\n",
    "from data_utils import get_loaders, get_svhn_data_loaders, get_mnist_data_loaders, get_usps_data_loaders\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(encoder_path, classifier_path):\n",
    "   model = CNNClassifier()\n",
    "   encoder = CNNEncoderV1()\n",
    "   classifier = Classifier()\n",
    "\n",
    "   encoder.load_state_dict(torch.load(encoder_path, map_location=torch.device('cpu')))\n",
    "   classifier.load_state_dict(torch.load(classifier_path, map_location=torch.device('cpu')))\n",
    "  \n",
    "   model.encoder = encoder\n",
    "\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "path_prefix = \"/Users/edmundyoung/Desktop/Princeton/Courses/S23/COS429/FinalProject/COS429_FINAL\"\n",
    "\n",
    "models = {}\n",
    "models[\"mnist_svhn\"] = load_model(path_prefix + \"/weights/MNIST_on_SVHN_encoder.pt\", path_prefix + \"/weights/1/categorizer_{'mnist'}.pt\")\n",
    "models[\"mnist_usps\"] = load_model(path_prefix + \"/weights/MNIST_on_USPS_encoder.pt\", path_prefix + \"/weights/1/categorizer_{'mnist'}.pt\")\n",
    "models[\"svhn_mnist\"] = load_model(path_prefix + \"/weights/SVHN_on_MNIST_encoder.pt\", path_prefix + \"/weights/3/categorizer_{'svhn'}.pt\")\n",
    "models[\"svhn_usps\"] = load_model(path_prefix + \"/weights/SVHN_on_USPS_encoder.pt\", path_prefix + \"/weights/3/categorizer_{'svhn'}.pt\")\n",
    "models[\"usps_mnist\"] = load_model(path_prefix + \"/weights/USPS_on_MNIST_encoder.pt\", path_prefix + \"/weights/2/categorizer_{'usps'}.pt\")\n",
    "models[\"usps_svhn\"] = load_model(path_prefix + \"/weights/USPS_on_SVHN_encoder.pt\", path_prefix + \"/weights/2/categorizer_{'usps'}.pt\")\n",
    "\n",
    "# put it in evaluation mode for inference\n",
    "for i in models.values():\n",
    "    i.eval()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = models[\"mnist_svhn\"].classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines two global scope variables to store our gradients and activations\n",
    "gradients = None\n",
    "activations = None\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "  global gradients # refers to the variable in the global scope\n",
    "  print('Backward hook running...')\n",
    "  gradients = grad_output\n",
    "  # In this case, we expect it to be torch.Size([batch size, 1024, 8, 8])\n",
    "  print(f'Gradients size: {gradients[0].size()}') \n",
    "  # We need the 0 index because the tensor containing the gradients comes\n",
    "  # inside a one element tuple.\n",
    "\n",
    "def forward_hook(module, args, output):\n",
    "  global activations # refers to the variable in the global scope\n",
    "  print('Forward hook running...')\n",
    "  activations = output\n",
    "  # In this case, we expect it to be torch.Size([batch size, 1024, 8, 8])\n",
    "  print(f'Activations size: {activations.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_hook = layer.register_full_backward_hook(backward_hook)\n",
    "forward_hook = layer.register_forward_hook(forward_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "svhn = get_svhn_data_loaders()\n",
    "mnist = get_mnist_data_loaders()\n",
    "usps = get_usps_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label: 9')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_iterator = iter(svhn['train'])\n",
    "images, label = train_data_iterator.__next__()\n",
    "\n",
    "image = images[0]\n",
    "# display the image\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image[0], cmap='gray')\n",
    "ax.set_title('Label: {}'.format(label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4h/h9s2_21x30jg2k3683jxrjv40000gn/T/ipykernel_12107/4031239319.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mnist_svhn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/cos429/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cos429/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cos429/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "models[\"mnist_svhn\"](image.unsqueeze(0)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CNNClassifier' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4h/h9s2_21x30jg2k3683jxrjv40000gn/T/ipykernel_11764/2358155042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"weights/MNIST_on_SVHN_encoder.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"weights/1/categorizer_{'mnist'}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGradCam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgrad_cam_superimposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuperimpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memphasize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4h/h9s2_21x30jg2k3683jxrjv40000gn/T/ipykernel_11764/3671994352.py\u001b[0m in \u001b[0;36mGradCam\u001b[0;34m(model, img_array, layer_name, eps)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     gradModel = Model(\n\u001b[0;32m---> 20\u001b[0;31m                         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \t\t\toutputs=[model.get_layer(layer_name).output,\n\u001b[1;32m     22\u001b[0m \t\t\t\tmodel.output])\n",
      "\u001b[0;32m~/miniconda3/envs/cos429/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1270\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CNNClassifier' object has no attribute 'inputs'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5026dcc8faa901074ac5884a0e073697a2ad80a01d5be01ad3120f1331c9eac0"
  },
  "kernelspec": {
   "display_name": "cos429",
   "language": "python",
   "name": "cos429"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
