{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradCam Analysis\n",
    "\n",
    "Note: Reused code from https://towardsdatascience.com/grad-cam-in-pytorch-use-of-forward-and-backward-hooks-7eba5e38d569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/Users/edmundyoung/Desktop/Princeton/Courses/S23/COS429/FinalProject/COS429_FINAL\")\n",
    "sys.path.append(\"/Users/edmundyoung/Desktop/Princeton/Courses/S23/COS429/FinalProject/COS429_FINAL/models\")\n",
    "sys.path.append(\"/Users/edmundyoung/Desktop/Princeton/Courses/S23/COS429/FinalProject/COS429_FINAL/data\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from models import CNNClassifier, CNNEncoderV1, Classifier\n",
    "from data_utils import get_loaders, get_svhn_data_loaders, get_mnist_data_loaders, get_usps_data_loaders\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(encoder_path, classifier_path):\n",
    "   model = CNNClassifier()\n",
    "   encoder = CNNEncoderV1()\n",
    "   classifier = Classifier()\n",
    "\n",
    "   encoder.load_state_dict(torch.load(encoder_path, map_location=torch.device('cpu')))\n",
    "   classifier.load_state_dict(torch.load(classifier_path, map_location=torch.device('cpu')))\n",
    "  \n",
    "   model.encoder = encoder\n",
    "\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CNNClassifier(\n",
      "  (encoder): CNNEncoderV1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (linearize): Linear(in_features=800, out_features=500, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (hidden): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "path_prefix = \"/Users/edmundyoung/Desktop/Princeton/Courses/S23/COS429/FinalProject/COS429_FINAL\"\n",
    "\n",
    "models = {}\n",
    "models[\"mnist_svhn\"] = load_model(prefix + \"/weights/MNIST_on_SVHN_encoder.pt\", prefix + \"/weights/1/categorizer_{'mnist'}.pt\")\n",
    "models[\"mnist_usps\"] = load_model(prefix + \"/weights/MNIST_on_USPS_encoder.pt\", prefix + \"/weights/1/categorizer_{'mnist'}.pt\")\n",
    "models[\"svhn_mnist\"] = load_model(prefix + \"/weights/SVHN_on_MNIST_encoder.pt\", prefix + \"/weights/3/categorizer_{'svhn'}.pt\")\n",
    "models[\"svhn_usps\"] = load_model(prefix + \"/weights/SVHN_on_USPS_encoder.pt\", prefix + \"/weights/3/categorizer_{'svhn'}.pt\")\n",
    "models[\"usps_mnist\"] = load_model(prefix + \"/weights/USPS_on_MNIST_encoder.pt\", prefix + \"/weights/2/categorizer_{'usps'}.pt\")\n",
    "models[\"usps_svhn\"] = load_model(prefix + \"/weights/USPS_on_SVHN_encoder.pt\", prefix + \"/weights/2/categorizer_{'usps'}.pt\")\n",
    "\n",
    "# put it in evaluation mode for inference\n",
    "for i in models.values():\n",
    "    i.eval()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = models[\"mnist_svhn\"].encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines two global scope variables to store our gradients and activations\n",
    "gradients = None\n",
    "activations = None\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "  global gradients # refers to the variable in the global scope\n",
    "  print('Backward hook running...')\n",
    "  gradients = grad_output\n",
    "  # In this case, we expect it to be torch.Size([batch size, 1024, 8, 8])\n",
    "  print(f'Gradients size: {gradients[0].size()}') \n",
    "  # We need the 0 index because the tensor containing the gradients comes\n",
    "  # inside a one element tuple.\n",
    "\n",
    "def forward_hook(module, args, output):\n",
    "  global activations # refers to the variable in the global scope\n",
    "  print('Forward hook running...')\n",
    "  activations = output\n",
    "  # In this case, we expect it to be torch.Size([batch size, 1024, 8, 8])\n",
    "  print(f'Activations size: {activations.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_hook = layer.register_full_backward_hook(backward_hook)\n",
    "forward_hook = layer.register_forward_hook(forward_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "svhn = get_svhn_data_loaders()\n",
    "mnist = get_mnist_data_loaders()\n",
    "usps = get_usps_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label: 1')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_iterator = iter(svhn['train'])\n",
    "images, label = train_data_iterator.__next__()\n",
    "\n",
    "image = images[0]\n",
    "# display the image\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image[0], cmap='gray')\n",
    "ax.set_title('Label: {}'.format(label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4h/h9s2_21x30jg2k3683jxrjv40000gn/T/ipykernel_11850/4031239319.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mnist_svhn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/cos429/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cos429/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cos429/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "models[\"mnist_svhn\"](image.unsqueeze(0)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CNNClassifier' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4h/h9s2_21x30jg2k3683jxrjv40000gn/T/ipykernel_11764/2358155042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"weights/MNIST_on_SVHN_encoder.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"weights/1/categorizer_{'mnist'}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGradCam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgrad_cam_superimposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuperimpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memphasize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4h/h9s2_21x30jg2k3683jxrjv40000gn/T/ipykernel_11764/3671994352.py\u001b[0m in \u001b[0;36mGradCam\u001b[0;34m(model, img_array, layer_name, eps)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     gradModel = Model(\n\u001b[0;32m---> 20\u001b[0;31m                         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \t\t\toutputs=[model.get_layer(layer_name).output,\n\u001b[1;32m     22\u001b[0m \t\t\t\tmodel.output])\n",
      "\u001b[0;32m~/miniconda3/envs/cos429/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1270\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CNNClassifier' object has no attribute 'inputs'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5026dcc8faa901074ac5884a0e073697a2ad80a01d5be01ad3120f1331c9eac0"
  },
  "kernelspec": {
   "display_name": "cos429",
   "language": "python",
   "name": "cos429"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
